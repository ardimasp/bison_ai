Authors,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Affiliations,Authors with affiliations,Abstract,Author Keywords,Index Keywords,Molecular Sequence Numbers,Chemicals/CAS,Manufacturers,Funding Details,Funding Text 1,References,Correspondence Address,Editors,Sponsors,Publisher,Conference name,Conference date,Conference location,Conference code,ISSN,ISBN,CODEN,PubMed ID,Language of Original Document,Abbreviated Source Title,Document Type,Publication Stage,Open Access,Source,EID
"Winoto A.S., Kristianus M., Premachandra C.","57215928509;57215930248;25926589200;","Small and Slim Deep Convolutional Neural Network for Mobile Device",2020,"IEEE Access","8",, 9126546,"125210","125222",,1,"10.1109/ACCESS.2020.3005161","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088704332&doi=10.1109%2fACCESS.2020.3005161&partnerID=40&md5=b1dd0997748bdabf696b2a178f8500c3","Department of Computer Science, Binus University, Jakarta, 135-8548, Indonesia; Department of Electronic Engineering, School of Engineering Graduate School of Engineering and Science, Shibaura Institute of Technology, Tokyo, Japan","Winoto, A.S., Department of Computer Science, Binus University, Jakarta, 135-8548, Indonesia; Kristianus, M., Department of Computer Science, Binus University, Jakarta, 135-8548, Indonesia; Premachandra, C., Department of Electronic Engineering, School of Engineering Graduate School of Engineering and Science, Shibaura Institute of Technology, Tokyo, Japan","Recent development of deep convolutional neural networks (DCNN) devoted in creating a slim model for devices with lower specification such as embedded, mobile hardware, or microcomputer. Slim model can be achieved by minimizing computational complexity which theoretically will make processing time faster. Therefore, our focus is to build an architecture with minimum floating-point operation per second (FLOPs). In this work, we propose a small and slim architecture which later will be compared to state-of-the-art models. This architecture will be implemented into two models which are CustomNet and CustomNet2. Each of these models implements 3 convolutional blocks which reduce the computational complexity while maintains its accuracy and able to compete with state-of-the-art DCNN models. These models will be trained using ImageNet, CIFAR 10, CIFAR 100 and other datasets. The result will be compared based on accuracy, complexity, size, processing time, and trainable parameter. From the result, we found that one of our models which is CustomNet2, is better than MobileNet, MobileNet-v2, DenseNet, NASNetMobile in accuracy, trainable parameter, and complexity. For future implementation, this architecture can be adapted using region based DCNN for multiple object detection. © 2013 IEEE.","Artificial neural network; deep learning; image recognition; machine learning","Complex networks; Computational complexity; Computer architecture; Convolution; Deep neural networks; Digital arithmetic; Network architecture; Object detection; Floating point operations; Mobile hardware; Multiple-object detections; Processing time; Region-based; State of the art; Convolutional neural networks",,,,,"This work was supported in part by the Branding Research Fund of Shibaura Institute of Technology.","Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proc. ICLR, pp. 1-14. , San Diego, CA, USA; He, K., Gkioxari, G., Dollár, P., Girshick, R., (2017) Mask R-CNN, , http://arxiv.org/abs/1703.06870; He, K., Gkioxari, G., Dollár, P., Girshick, R., Mask R-CNN (2017) Proc. IEEE Int. Conf. Comput. Vis. (ICCV), pp. 2980-2988. , Venice, Italy, Oct; Lin, T.-Y., Goyal, P., Girshick, R., He, K., Dollar, P., Focal loss for dense object detection (2017) Proc. IEEE Int. Conf. Comput. Vis. (ICCV), pp. 2999-3007. , Venice, Italy, Oct; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 580-587. , Columbus, OH, USA, Jun; Girshick, R., Fast R-CNN (2015) Proc. IEEE Int. Conf. Comput. Vis. (ICCV), pp. 1440-1448. , Santiago, Chile, Dec; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards realtime object detection with region proposal networks (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (6), pp. 1137-1149. , Jun; Dong, C., Loy, C.C., He, K., Tang, X., Image super-resolution using deep convolutional networks (2016) IEEE Trans. Pattern Anal. Mach. Intell., 38 (2), pp. 295-307. , Feb; Kim, J., Lee, J.K., Lee, K.M., Accurate image super-resolution using very deep convolutional networks (2016) Proc. IEEE Conf. Comput. Vis. Pat-tern Recognit. (CVPR), pp. 1646-1654. , Las Vegas, NV, USA, Jun; Guo, H., Wang, S., Fan, J., Li, S., Learning automata based incremental learning method for deep neural networks (2019) IEEE Access, 7, pp. 41164-41171; Zhang, H., He, J., Ko, S.-B., Improved hybrid memory cube for weight-sharing deep convolutional neural networks (2019) Proc. IEEE Int. Conf. Artif. Intell. Circuits Syst. (AICAS), pp. 122-126. , Hsinchu, Taiwan, Mar; Subhi, M.A., Ali, S., A deep convolutional neural network for food detection and recognition (2018) Proc. IEEE-EMBS Conf. Biomed. Eng. Sci. (IECBES), pp. 284-287. , Sarawak, Malaysia, Dec; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2017) Commun. ACM, 60 (6), pp. 84-90. , May; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 770-778. , Las Vegas, NV, USA, Jun; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., (2017) MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications, , http://arxiv.org/abs/1704.04861; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.-C., MobileNetV2: Inverted residuals and linear bottlenecks (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 4510-4520. , Salt Lake City, UT, USA, Jun; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., You only look once: Unified, real-time object detection (2016) Proc. IEEE Conf. Com-put. Vis. Pattern Recognit. (CVPR), pp. 779-788. , Las Vegas, NV, USA, Jun; Redmon, J., Farhadi, A., YOLO9000: Better, faster, stronger (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 6517-6525. , Honolulu, HI, USA, Jul; Redmon, J., Farhadi, A., (2018) YOLOv3: An Incremental Improvement, , http://arxiv.org/abs/1804.02767; Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C., Berg, A.C., SSD: Single shot MultiBox detector (2016) Proc. Comput. Vis. (ECCV), pp. 21-37; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1-9. , Boston, MA, USA, Jun; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2818-2826. , Las Vegas, NV, USA, Jun; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A., (2016) Inceptionv4, Inception-ResNet and the Impact of Residual Connections on Learning, , http://arxiv.org/abs/1602.07261; Freeman, I., Roese-Koerner, L., Kummert, A., Effnet: An efficient structure for convolutional neural networks (2018) Proc. 25th IEEE Int. Conf. Image Process. (ICIP), pp. 6-10. , Athens, Greece, Oct; Sun, S., Pang, J., Shi, J., Yi, S., Ouyang, W., (2019) FishNet: A Versatile Backbone for Image, Region, and Pixel Level Prediction, , http://arxiv.org/abs/1901.03495; Zoph, B., Vasudevan, V., Shlens, J., Le, Q.V., Learning transferable architectures for scalable image recognition (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 8697-8710. , Salt Lake City, UT, USA, Jun; Opitz, D., Maclin, R., Popular ensemble methods: An empirical study (1999) J. Artif. Intell. Res., 11, pp. 169-198. , Aug; Zhou, Z.H., Combination methods (2012) Ensemble Methods: Foundations and Algorithms. New York, pp. 68-69. , NY, USA: CRC Press ch. 4 sec. 2; Huang, G., Liu, Z., Van Maaten Der, L., Weinberger, K.Q., Densely connected convolutional networks (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2261-2269. , Honolulu, HI, USA, Jul; Chen, G., Chen, P., Shi, Y., Hsieh, C.-Y., Liao, B., Zhang, S., (2019) Rethinking the Usage of Batch Normalization and Dropout in the Training of Deep Neural Networks, , http://arxiv.org/abs/1905.05928; Ioffe, S., Szegedy, C., (2015) Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, , http://arxiv.org/abs/1502.03167; Abadi, M., (2016) TensorFlow: Large-scale Machine Learning on Heterogeneous Distributed Systems, , http://arxiv.org/abs/1603.04467; Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y., Reading digits in natural images with unsupervised feature learning (2011) Proc. NIPS, (2), p. 5; Stallkamp, J., Schlipsing, M., Salmen, J., Igel, C., The German traffic sign recognition benchmark: A multi-class classification competition (2011) Proc. Int. Joint Conf. Neural Netw., pp. 1453-1460. , Jul; Krizhevsky, A., Learning multiple layers of features from tiny images (2009) Computer Science. Toronto, , ON, Canada: Univ. Toronto, ON, Canada, Apr; Chrabaszcz, P., Loshchilov, I., Hutter, F., (2017) A Downsampled Variant of ImageNet As An Alternative to the CIFAR Datasets, , http://arxiv.org/abs/1707.08819; Premachandra, C., Thanh, D.N.H., Kimura, T., Kawanaka, H., A study on hovering control of small aerial robot by sensing existing floor features (2020) IEEE/CAA J. Automatica Sinica, 7 (4), pp. 1016-1025. , Jul; Premachandra, C., Gohara, R., Ninomiya, T., Kato, K., Smooth automatic stopping for ultra-compact vehicles (2019) IEEE Trans. Intell. Vehicles, 4 (4), pp. 561-568. , Dec; Nakajima, K., Premachandra, C., Kato, K., 3D environment mapping and self-position estimation by a small ying robot mounted with a movable ultrasonic range sensor (2017) J. Electr. Syst. Inf. Technol., 4 (2), pp. 289-298. , Sep; Premachandra, C., Ueda, D., Kato, K., Speed-up automatic quadcopter position detection by sensing propeller rotation (2019) IEEE Sensors J., 19 (7), pp. 2758-2766. , Apr; Premachandra, C., Otsuka, M., Gohara, R., Ninomiya, T., Kato, K., A study on development of a hybrid aerial terrestrial robot system for avoiding ground obstacles by fiight (2019) IEEE/CAA J. Automatica Sinica, 6 (1), pp. 327-336. , Jan; Yamazaki, Y., Tamaki, M., Premachandra, C., Perera, C.J., Sumathipala, S., Sudantha, B.H., Victim detection using UAV with on-board voice recognition system (2019) Proc. 3rd IEEE Int. Conf. Robotic Comput. (IRC), pp. 555-559. , Feb","Winoto, A.S.; Department of Computer Science, Indonesia; email: deus484@gmail.com",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85088704332
"Winoto A.S., Kristianus M., Linardi B., Warnars H.L.H.S.","57215928509;57215930248;57215925695;57219696428;","Proposed Autonomous Vehicle Framework for Safe Driving",2019,"2019 7th International Conference on Cyber and IT Service Management, CITSM 2019",,, 8965384,"","",,,"10.1109/CITSM47753.2019.8965384","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082399469&doi=10.1109%2fCITSM47753.2019.8965384&partnerID=40&md5=a5630bbbf45fb52797120ee417ac88ae","School of Computer Science, Computer Science Department, Indonesia; BINUS Graduate Program, Doctor of Computer Science, Bina Nusantara University, Computer Science Department, Jakarta, 11480, Indonesia","Winoto, A.S., School of Computer Science, Computer Science Department, Indonesia; Kristianus, M., School of Computer Science, Computer Science Department, Indonesia; Linardi, B., School of Computer Science, Computer Science Department, Indonesia; Warnars, H.L.H.S., BINUS Graduate Program, Doctor of Computer Science, Bina Nusantara University, Computer Science Department, Jakarta, 11480, Indonesia","The proposed idea to improve the usage of an autonomous vehicle to increase safe driving based on the DARPA project, which already has shown the bright future of the autonomous vehicle. This paper proposes a new idea regarding the sensors and the autonomous vehicle framework, such as the usage of some algorithms and new UI along with the data logger. Moreover, the use of a LIDAR sensor is extended, along with a stereo camera and also ultrasonic sensor to make it more precise. Then, a calibration system is made for the stereo camera, which will take help from the ultrasonic sensor. Not the only ultrasonic, camera, and LIDAR, and IMU and GPS sensor are used to know the angle of x, y, and z of our vehicle. Both IMU and GPS are helping in the perception and mostly in the RNDF Localization that will be used in the pathfinding, planning, and control. The global Dynamic-Window approach is applied for the path selection algorithm and combining it with the Autonomous System Approach. The speed selection algorithm will decide on the speed limit and the camera. Not only that but the implement the Inter-Vehicle Algorithm is implemented, which makes the vehicles can exchange information with the other vehicles in the radius of the vehicle. Which all of this together can make a safer driving environment, not only for cars but another vehicle as well. Hope this framework can be used for any other vehicle project and becoming the base of all autonomous vehicle. © 2019 IEEE.","Autonomous Vehicle Framework; LIDAR; NRDF; Safe Driving; Stereo Camera","Automobile drivers; Cameras; Optical radar; Stereo image processing; Ultrasonic sensors; Autonomous systems; Calibration system; Driving environment; NRDF; Path selection algorithms; Safe driving; Selection algorithm; Stereo cameras; Autonomous vehicles",,,,,,"Buehler, M., Iagnemma, K., Singh, S., (2007) The 2005 DARPA Grand Challenge: The Great Robot Race, , Springer, Berlin; Montemerlo, M., Thrun, S., Dahlkamp, H., Winning the darpa grand challenge with an ai robot (2006) The Twenty-First National Conference on Artificial Intelligence and the Eighteenth Innovative Applications of Artificial Intelligence Conference, , Boston, MA; Montemerlo, M., Becker, J., Bhat, S., Junior: The standford entry in the urban challenge (2008) Journal of Field Robotics, 25 (9), pp. 569-597. , Sep; Thrun, S., Montemerlo, M., Dahlkamp, H., Stanley: The robot that won the darpa grand challenge (2016) Journal of Field Robotic, 23 (9), pp. 661-692. , Sep; Hall, R., Kolski, S., MacEk, K., 2D laser-based probabilistic motion tracking in urban-like environments (2009) Journal of Brazilian Society of Mechanical Sciences and Engineering, 31 (2), pp. 83-96. , Jun; Stavens, D., Hoffmann, G., Thrun, S., Online speed adaptation using supervised learning for high-speed, off-road autonomous driving (2007) Proceedings of the 20th International Joint Conference on Artifical Intelligence: IJCAI'07, , Hyderabad, India; HAD Site Ibeo Automotive Systems GmbH, Hamburg Ibeo Automotive Systems GmbH, , http://www.ibeo-as.com/had, ibeo, Internet, [Oct. 23 2018]; Deems, J.S., Painter, T.H., Finnegan, D.C., Lidar measurement of snow depth: A review (2013) Journal of Glaciology, 59 (215), pp. 467-479. , Jul; Adi, K., Widodo, C.E., Distance measurement with a stereo camera (2017) International Journal of Innovative Research in Advanced Engineering (IJIRAE), 4 (11), pp. 24-27. , Nov; Mrovlje, J., Vrancic, D., Distance measuring based on stereoscopic pictures (2008) 9th International PhD Workshop on Systems and Control: Young Generation Viewpoint, , Izola, Slovenia; Zivingy, M., Object distance measurement by stereo vision (2013) International Journal of Science and Applied Information Technology (IJSAIT), 2, pp. 5-8. , Jan; Mohammad, T., Using ultrasonic and infrared sensors for distance measurement (2009) International Journal of Mechanical and Mechatronics Engineering, 3, pp. 267-272; Gilabert, G.B., Blanes, F., Simo, J.S., Perez, P., Using infrared sensors for distance measurement in mobile robots (2002) Robotics and Autonomous System, 40, pp. 255-266. , Sep; Koval, L., Vanus, J., Bilik, P., Distance measuring by ultrasonic sensor (2016) IFAC-PapersOnLine, 49, pp. 153-158; Abdulqadir, O.Y., Abduladheem, W.R., Distance measurement using dual laser source and image processing techniques (2015) Journal of Al Rafidain University Colleg, (35), pp. 266-286; Alsultanny, Y.A., Laser beam analysis using image processing (2006) Journal of Computer Science, 2 (1), pp. 109-113; Siegwart, R., Nourbakhsh, I.R., (2004) Introduction to Autonomous Mobile Robots, , Cambridge, MA: The MIT Press; Chakravorty, S., Kumar, S., Generalized sampling-based motion planners (2011) 2009 IEEE Transaction on System, Man, and Cybernetics, 41; Rarath, D., Sharma, M., Mane, A., Dabral, P., Ade, R., Computer independent data transfer device (2017) International Journal of Recent Contributions from Engineering, Science & IT (IJES), 5 (2), pp. 72-81; Tsugawa, S., Inter-vehicle communication and their application to intelligent vehicles: An overview (2002) IEEE Intelligent Vehicle Symposium, 2002; Seetharaman, G., Lakhotia, A., Blasch, E.P., Unmanned vehicles come of age: The darpa grand challenge (2006) Computer, 39 (12), pp. 26-29; Application Note: Optical Encoders and LiDAR Scanning, , http://www.renishaw.com/en/opticalencoders-And-lidar-scanning-39244, Renishawplc. Internet, [Nov. 22 2018]; Mukhtar L, A., Tang, B.X.T., Vehicle detection techniques for collision avoidance systems: A review (2015) IEEE Transactions on Intelligent Transportation Systems, 16 (5), pp. 2318-2338. , Oct; Grunewald, S.J., 3D Technology-Powered Self-Driving Cars Will Be a Personal Privacy Nightmare, , http://3dprint.com/116569/self-driving-cars-privacy, Internet, [Dec. 6 2018]",,,,"Institute of Electrical and Electronics Engineers Inc.","7th International Conference on Cyber and IT Service Management, CITSM 2019","6 November 2019 through 7 November 2019",,157081,,9781728129099,,,"English","Int. Conf. Cyber IT Serv. Manag., CITSM",Conference Paper,"Final","",Scopus,2-s2.0-85082399469
