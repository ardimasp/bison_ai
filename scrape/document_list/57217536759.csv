Authors,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Affiliations,Authors with affiliations,Abstract,Author Keywords,Index Keywords,Molecular Sequence Numbers,Chemicals/CAS,Manufacturers,Funding Details,References,Correspondence Address,Editors,Sponsors,Publisher,Conference name,Conference date,Conference location,Conference code,ISSN,ISBN,CODEN,PubMed ID,Language of Original Document,Abbreviated Source Title,Document Type,Publication Stage,Open Access,Source,EID
"Bimorogo S.D., Kusuma G.P.","57217536759;24474615100;","A comparative study of pretrained convolutional neural network model to identify plant diseases on android mobile device",2020,"International Journal of Advanced Trends in Computer Science and Engineering","9","3",,"2824","2833",,2,"10.30534/ijatcse/2020/53932020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087346187&doi=10.30534%2fijatcse%2f2020%2f53932020&partnerID=40&md5=94a469ce4db818d7c1654de1189eea34","Computer Science Department, Bina Nusantara University, Jakarta, 11480, Indonesia","Bimorogo, S.D., Computer Science Department, Bina Nusantara University, Jakarta, 11480, Indonesia; Kusuma, G.P., Computer Science Department, Bina Nusantara University, Jakarta, 11480, Indonesia","Optimization of mobile devices to be used as early identification tools of plant diseases using an application based on Convolutional Neural Network (CNN), with a high degree of accuracy and low power consumption is the focus of this study. The study was conducted using a dataset consisting of 38 different classes of PlantVillage dataset, which were then expanded using 2 classes of coffee plants and 4 classes of rice plants. The models that are going to be tested and compared consists of MobileNet V2, NasNet Mobile, DenseNet 121 layer, and InceptionV3. In the experiments, it was found that there was a decrease in accuracy when the application was run on a mobile device when compared to when it was run on a PC. Experiments also show that InceptionV3 is the most stable model and reaches the highest level of accuracy, which is 98.45% on mobile devices. However, InceptionV3 consumes a lot of resources when used on mobile devices. Meanwhile, MobileNet V2, NasNet Mobile, dan DenseNet 121, do not consume a lot of resources when tested on mobile devices. In terms of accuracy, NasNet Mobile reached 97.31%, then MobileNet V2 reached 96.55%, and DenseNet 121 reached 96.21%. Based on the research criteria, it can be concluded that the CNN model that is most suitable to be used on mobile devices is NasNet Mobile. Because it has a high degree of accuracy with low resource consumption. © 2020, World Academy of Research in Science and Engineering. All rights reserved.","Convolutional Neural Networks; Deep Learning; Mobile Application; Plant Disease Identification; PlantVillage Dataset",,,,,,"Bock, C. H., Poole, G. H., Parker, P. E., Gottwald, T. R., Plant disease severity estimated visually, by digital photography and image analysis, and by hyperspectral imaging, CRC (2010) Crit. Rev. Plant Sci, 29. , https://doi.org/10.1080/07352681003617285; Gadade, H. D., Kirange, D. K., Machine Learning Approach towards Tomato Leaf Disease Classification (2020) Int. J. Adv. Trends Comput. Sci. Eng, 9. , https://doi.org/10.30534/ijatcse/2020/67912020; Saha, R., Neware, S., Orange Fruit Disease Classification using (2020) Int. J. Adv. Trends Comput. Sci. Eng, 9. , https://doi.org/10.30534/ijatcse/2020/211922020; Han, J., Kamber, M., Pei, J., (2012) Data Mining Concepts and Techniques, , 3rd ed, Elsevier Inc., Waltham; Krizhevsky, A., Sutskever, I., Hinton, G. E., ImageNet classification with deep convolutional neural networks Adv. Neural Inf. Process. Syst, 2; 1097; Patterson, J., Gibson, A., (2016) Deep Learning A Practitioner’s Approach, , 1st ed, oreilly, boston; Zhang, X., Qiao, Y., Meng, F., Fan, C., Zhang, M., Identification of Maize Leaf Diseases Using Improved Deep Convolutional Neural Networks (2018) IEEE Access, 6. , https://doi.org/10.1109/ACCESS.2018.2844405; Ferentinos, K. P., Deep learning models for plant disease detection and diagnosis (2018) Comput. Electron. Agric, 145. , Elsevier; Too, E. C., Yujian, L., Njuki, S., Yingchun, L., A comparative study of fine-tuning deep learning models for plant disease identification (2018) Comput. Electron. Agric, , Elsevier; Brahimi, M., Arsenovic, M., Laraba, S., Sladojevic, S., (2018) Deep Learning for Plant Diseases: Detection and Saliency Map Visualisation Deep Learning For Plant Diseases: Detection and Saliency map Visualization, , https://doi.org/10.1007/978-3-319-90403-0_6; Jadhav, S. B., Udupi, V. R., Patil, S. B., Cnn, D., Convolutional neural networks for leaf image-based plant disease classification (2019) International Journal of Artificial Intelligence, 8; Hughes, D., Salathe, Marcel, (2015) An open access repository of images on plant health to enable the development of mobile disease diagnostics; Syamsuri, B., Kusuma, G. P., Plant Disease Classification Using Lite Pretrained Deep Convolutional Neural Network on Android Mobile Device (2019) International Journal of Innovative Technology and Exploring Engineering, 9. , https://doi.org/10.35940/ijitee.B6647.129219; Do, H., (2019) Rice Diseases Image Dataset: An image dataset for rice and its diseases, , https://www.kaggle.com/minhhuy2810/rice-diseases-image-dataset, [Online]. Available: [Accessed: 27-Jan-2020]; Francisco, A. K. G., (2019) Rice Diseases DataSet, , https://github.com/aldrin233/RiceDiseases-DataSet, [Online].Available: [Accessed: 27-Jan-2020]; Sandler, M., Howard, A. G., Zhu, M., Zhmoginov, A., Chen, L. C., MobileNetV2: Inverted Residuals and Linear Bottlenecks (2018) Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit; Zoph, B., Vasudevan, V., Shlens, J., Le, Q. V., Learning Transferable Architectures for Scalable Image Recognition (2018) Proc. IEEE Conf. Comput. Vis. pattern Recognit, p. 8697; Zoph, B., Vasudevan, V., Shlens, J., Le, Q. V, (2017) AutoML for large scale image classification and object detection, , https://ai.googleblog.com/2017/11/automl-for-large-scale-image.html, [Online].Available: [Accessed: 12-Dec-2019]; Szegedy, C., Vanhoucke, V., Shlens, J., (2014) Rethinking the Inception Architecture for Computer Vision; Huang, G., Liu, Z., Maaten van der, L., Weinberger, K., (2016) Densely Connected Convolutional Networks; Vanetti, M., (2007) Confusion Matrix Online Calculator, Confusion Matrix Online Calculator, , http://www.marcovanetti.com/pages/cfmatrix/?noc=44, [Online]. Available: [Accessed: 13-March-2020]",,,,"World Academy of Research in Science and Engineering",,,,,22783091,,,,"English","Int. J. Adv. Trends Comput. Sci. Eng.",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85087346187
