Authors,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Affiliations,Authors with affiliations,Abstract,Author Keywords,Index Keywords,Molecular Sequence Numbers,Chemicals/CAS,Manufacturers,Funding Details,References,Correspondence Address,Editors,Sponsors,Publisher,Conference name,Conference date,Conference location,Conference code,ISSN,ISBN,CODEN,PubMed ID,Language of Original Document,Abbreviated Source Title,Document Type,Publication Stage,Open Access,Source,EID
"Martinez J.J.L., Dewanti S.S.","57197749074;57215306683;","Multimodal interfaces: A study on speech-hand gesture recognition",2019,"2019 International Conference on Information and Communications Technology, ICOIACT 2019",,, 8938421,"196","200",,,"10.1109/ICOIACT46704.2019.8938421","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077963880&doi=10.1109%2fICOIACT46704.2019.8938421&partnerID=40&md5=b77ed5714ae00a3513e43db66944b105","Computer Science Department, Faculty of Computing and Media, Bina Nusantara University, Jakarta, 11480, Indonesia","Martinez, J.J.L., Computer Science Department, Faculty of Computing and Media, Bina Nusantara University, Jakarta, 11480, Indonesia; Dewanti, S.S., Computer Science Department, Faculty of Computing and Media, Bina Nusantara University, Jakarta, 11480, Indonesia","One common unimodal human-computer interface is via a formal and discrete behavior on physical or virtual button clicks. That method may not be convenient for some people with knowledge or physical limitations. The raise for more pervasive, subtly blending computers in daily tasks may also find the method to be unnatural and inconvenient. Combination of modalities, or multimodal interaction is suggested to have advantages over unimodal input. Synergic multiple input and output modal is more expressive and natural. Specifically, studies have suggested that a combination of speech and gesture is preferred as being more effective and natural than speech or gesture alone. There are many successful approaches in providing robust gesture-only and speech-only interfaces, however, under extreme environments, unimodal approaches have user experience issues. To address the issue, the authors seek to explore and conduct a preliminary study and evaluation of speech-hand gesture recognition using Leap Motion and Windows Speech Recognition API. A conceptual framework would be developed as a result of this study. © 2019 IEEE","Gesture Recognition; Human Computer Interaction; Multimodal User Interface; Speech Recognition","Blending; Gesture recognition; Human computer interaction; Interactive computer systems; Palmprint recognition; Speech; User interfaces; Virtual reality; Conceptual frameworks; Extreme environment; Hand-gesture recognition; Human computer interfaces; Multi-Modal Interactions; Multi-modal interfaces; Multimodal user interface; Physical limitations; Speech recognition",,,,,"Lubar, S., Do not fold, spindle or mutilate: The cultural history of the punch card (1992) The Journal of American Culture, 15 (4), pp. 43-55. , December; Dotan, A., Input Devices, , http://www.slideshare.net/Amir_D/input-devices-1941161, Online; Freitas, D.Q., Gama, A.E.F., Figueiredo, L., Chaves, T.M., Oliveira, D.M., Teichrieb, V., Araujo, C., Development and evaluation of a kinect based motor rehabilitation game (2012) Simpósio Brasileiro de Jogos e Entretenimento Digital, 2012, Brasilia. SBC - Proceedings of SBGames; Singer, E., Larke, K., Bianciardi, D., LEMUR GuitarBot: MIDI robotic string instrument Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), , Montreal, Canada; Wong, E., Yuen, W., Choy, C., Designing wii controller: A powerful musical instrument in an interactive music performance system Proceedings of the 6th International Conference on Advances in Mobile Computing and Multimedia, pp. 82-87; Wexelblat, A., An approach to natural gesture in virtual environments (1995) ACM Transactions on Computer-Human Interactions, 2 (3), pp. 179-200; Dannenberg, R.B., CHI'90 workshop on multimedia and multimodal interface design (1990) SIGCHI Buletin, 22 (2), pp. 54-58. , M. M. B. a; Dumas, B., Multimodal interfaces: A survey of principles, models and frameworks (2009) Human Machine Interaction: Research Results of the Mmj Program, p. 3. , https://doi.org/10.1007/978-3-642-00437-7_1, Online.: Accessed 20 March 2019; Hauptmann, A.G., Speech and gestures for graphic image manipulation (1989) CHI'89 Proceeedings, pp. 241-245; Perakakis, M., Potaminos, A., A study in efficiency and modality usage in (2008) IEEE Transactions on Audio Speech and Language Processing (IEEE T AUDIO SPEECH), 16 (6), pp. 1194-1206. , September; (2011) Gesture, , http://en.wikipedia.org/wiki/Gesture, October Online; (2008) What Is Gesture Recognition, , http://whatis.techtarget.com/definition/0,sid9_gci212183,00.html, Online; Bolt, R.A., (1980) Put-That-There"": Voice and Gesture at the Graphics Interface, , Massachusetts Institute of Technology, Cambridge; Zimmerman, T.G., Lanier, J., Blanchard, C., Bryson, S., Harvill, Y., (1987) A Hand Gesture Interface Device, , VPL Research, Inc., Redwood City; Rekimoto, J., (2001) GestureWrist and GesturePad: Unobstrusive Wearable Interaction Devices, , Sony Computer Science Laboratories Inc., Shinagawa-ku; (2011) Sensory Therapy Cart - Music Therapy, , http://www.flaghouse.com/GestureTek-Immersive-Therapy-Cartitem-39306, Online; Survey of speech-hand gesture recognition or the development of multimodal interfaces in computer games (2010) ICME; Dumas, B., Multimodal interfaces: A survey of principles, models and frameworks (2009) Human Machine Interaction: Research Results of the Mmj Program, p. 3. , https://doi.org/10.1007/978-3-642-00437-7_1, Online.: Accessed 20 March 2019; Oviatt, S., Designing the user interface for multimodal speech and pen-based gesture applications: State-of-the-art systems and future research directions (2000) Human-Computer Interaction, 15 (4), pp. 263-322. , September Online. Research Gate; Kettebekov, S., Prosody Based Co-Analysis for Continuous Recognition of Co-Verbal Gestures, , Department of Computer Science and Engineering. Pennsylvania State University, PA, USA; Oviatt, S., From members to teams to committee - A robust approach to gestural and multimodal recognition (2000) IEEE Transactions on Neural Networks, 13 (4), pp. 972-982. , __ February Online. Research Gate,: Accessed 20 March 2019; Oviatt, S., Designing the user interface for multimodal speech and pen-based gesture applications: State-of-the-art systems and future research directions (2000) Human-Computer Interaction, 15 (4), pp. 263-322. , September Online. Research Gate; Colgan, A., (2014) How Does Leap Motion Controllers Work, , http://blog.leapmotion.com/hardware-to-software-how-does-the-leapmotion-controller-work/, Aug. Online. Leap Motion, Accessed: 22 March 2019; (2018) Speech Recognition, , https://docs.microsoft.com/enus/windows/uwp/design/input/speech-recognition, Oct. Online Windows Dev Center Accessed: 24 March 2019; (2017) Leap Motion Inc, , https://www.leapmotion.com/product, Online; Yong-Hee, L., Design of multimodal interface framework (2007) Advanced Communication Technology, the 9th International Conference on, 1, pp. 345-348; Wu, L., Multimodal integration - A statistical view (2000) IEEE Transactions on Multimedia, 1 (4), pp. 344-1341. , Online. Research Gate,: Accessed 19 March 2019",,,,"Institute of Electrical and Electronics Engineers Inc.","2nd International Conference on Information and Communications Technology, ICOIACT 2019","24 July 2019 through 25 July 2019",,156206,,9781728116556,,,"English","Int. Conf. Inf. Commun. Technol., ICOIACT",Conference Paper,"Final","",Scopus,2-s2.0-85077963880
