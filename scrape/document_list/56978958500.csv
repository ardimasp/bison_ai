Authors,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Affiliations,Authors with affiliations,Abstract,Author Keywords,Index Keywords,Molecular Sequence Numbers,Chemicals/CAS,Manufacturers,Funding Details,Funding Text 1,References,Correspondence Address,Editors,Sponsors,Publisher,Conference name,Conference date,Conference location,Conference code,ISSN,ISBN,CODEN,PubMed ID,Language of Original Document,Abbreviated Source Title,Document Type,Publication Stage,Open Access,Source,EID
"Ham H., Wesley J., Hendra","57192074819;56978958500;57194540356;","Computer vision based 3D reconstruction : A review",2019,"International Journal of Electrical and Computer Engineering","9","4",,"2394","2402",,5,"10.11591/ijece.v9i4.pp2394-2402","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066294717&doi=10.11591%2fijece.v9i4.pp2394-2402&partnerID=40&md5=0e994ca49db19e5cd1cd904016e3441c","Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, 11480, Indonesia","Ham, H., Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, 11480, Indonesia; Wesley, J., Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, 11480, Indonesia; Hendra, Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, 11480, Indonesia","3D reconstruction are used in many fields starts from the object reconstruction such as site, cultural artifacts in both ground and under the sea levels, medical imaging data, nuclear substantional. The scientist are beneficial for these task in order to learn, keep and better visual enhancement into 3D data. In this paper we differentiate the algorithm used depends on the input image: Single still image, RGB-Depth image, multiperspective of 2D images, and video sequences. The prior works also explained how the 3D reconstruction perform in many fields and using various algorithms. © 2019 Institute of Advanced Engineering and Science.","3D alignment; 3D point clouds; 3D reconstruction",,,,,"Binus University","The author also would like to acknowledge Bina Nusantara University for the grant research funding.","Anwer, A., Ali, S.S.A., Meriaudeau, F., Underwater online 3D mapping and scene reconstruction using low cost kinect RGB-D sensor (2016) 2016 6th International Conference on Intelligent and Advanced Systems (ICIAS), pp. 1-6. , http://ieeexplore.ieee.org/document/7824132/; Tsiafaki, D., Michailidou, N., Benefits and problems through the application of 3D technologies in archaeology: Recording, visualisation, representation and reconstruction (2015) Scientific Culture Tsiafaki & Michailidou Scientific Culture, 1 (3), pp. 37-45; Santoso, F., Garratt, M., Pickering, M., Asikuzzaman, M., 3D-mapping for visualisation of rigid structures: A review and comparative study (2015) IEEE Sensors Journal, PP (99), pp. 1-1. , http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7322186; Harjoko, A., Hujja, R.M., Awaludin, L., Low-cost 3D surface reconstruction using Stereo camera for small object (2017) 2017 International Conference on Signals and Systems (ICSigSys), pp. 285-289. , http://ieeexplore.ieee.org/document/7967057/; Evangelidis, G.D., Hansard, M., Horaud, R., Fusion of range and stereo data for high-resolution scene-modeling (2015) IEEE Transactions on Pattern Analysis and Machine Intelligence, 37 (11), pp. 2178-2192; (2017) Simple and Low Cost Scanner 3D System Based on a Time-of-Flight Ranging Sensor, pp. 3-7; Ravanelli, R., Nascetti, A., Crespi, M., Kinect V2 and Rgb stereo cameras integration for depth map enhancement (2016) ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, XLI-B5, pp. 699-702. , http://www.int-archphotogramm-remote-sens-spatial-inf-sci.net/XLI-B5/699/2016/isprs-archives-XLI-B5-699-2016.pdf, July; Yan, X., Yang, J., Yumer, E., Guo, Y., Lee, H., Perspective Transformer Nets: Learning Single-View 3D Object Reconstruction without 3D Supervision; Hao, Q., Cai, R., Li, Z., Zhang, L., Pang, Y., Wu, F., Rui, Y., Efficient 2D-to-3D correspondence filtering for scalable 3D object recognition (2013) Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, (1), pp. 899-906; Xian-Hua, J., Yuan-Qing, Z., (2014) Error Elimination Algorithm in 3D Image Reconstruction, 12 (4), pp. 2690-2696; Sepehrinour, M., Kasaei, S., Perspective reconstruction of non-rigid surfaces from single-view videos (2017) 2017 25th Iranian Conference on Electrical Engineering, ICEE 2017, pp. 1452-1458. , no. Icee20 17; Yao, J., Taylor, R., Assessing accuracy factors in deformable 2D/3D medical image registration using a statistical pelvis model (2003) Proceedings of the IEEE International Conference on Computer Vision, 2, pp. 1329-1334. , http://www.scopus.com/inward/record.url?eid=2-s2.0-0344983014&partnerID=tZOtx3y1; Hichem, G., Chouchene, F., Belmabrouk, H., 3D model reconstruction of blood vessels in the retina with tubular structure (2015) International Journal on Electrical Engineering and Informatics, 7 (4), pp. 724-734; Sumijan, S., Madenda, S., Harlan, J., Wibowo, E.P., Hybrids otsu method, feature region and mathematical morphology for calculating volume hemorrhage brain on ct-scan image and 3D reconstruction (2017) TELKOMNIKA (Telecommunication Computing Electronics and Control), 15 (1), p. 283. , http://journal.uad.ac.id/index.php/TELKOMNIKA/article/view/3146; Caregiver, F., Introduction, A., Traumatic, D., Tbi, M., Tbi, M., Tbis, S., Tbi, A., Changes, P., (2018) Fact Sheet Traumatic Brain Injury, pp. 1-6; Monterial, M., Marleau, P., Pozzi, S.A., Single-view 3-d reconstruction of correlated gamma-neutron sources (2017) IEEE Transactions on Nuclear Science, 64 (7), pp. 1840-1845; Saxena, A., Chung, S.H., Ng, A.Y., Depth reconstruction from a single still image (2007) Ijcv, 74 (1); Chang, A.X., Funkhouser, T., Guibas, L., Hanrahan, P., Huang, Q., Li, Z., Savarese, S., Yu, F., (2015) ShapeNet: An Information-Rich 3D Model Repository, , http://arxiv.org/abs/1512.03012; Rezende, D.J., Eslami, S.M.A., Mohamed, S., Battaglia, P., Jaderberg, M., Heess, N., (2016) Unsupervised Learning of 3D Structure from Images, , http://arxiv.org/abs/1607.00662; Wu, J., Xue, T., Lim, J.J., Tian, Y., Tenenbaum, J.B., Torralba, A., Freeman, W.T., Single image 3D interpreter network (2016) Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), Vol. 9910 LNCS, pp. 365-382; Fan, B., Rao, Y., Liu, W., Wang, Q., (2017) Region-Based Growing Algorithm for 3D Reconstruction from MRI Images, pp. 521-525; Nadu, T., (2015) Brain Tumor Segmentation of MRI Brain Images through FCM Clustering and Seeded Region Growing Technique, 10 (76), pp. 427-432; Zhang, M., Zhang, Z., Li, W., (2017) 3D Model Reconstruction Based on Plantar Image ' S Feature Segmentation, pp. 1-5; Juan, L., Gwun, O., A comparison of sift, PCA-sift and surf (2009) International Journal of Image Processing (IJIP), 3 (4), pp. 143-152; Yan, W., Shi, X., Yan, X., Wang, L., Computing OpenSURF on OpenCL and general purpose GPU (2013) International Journal of Advanced Robotic Systems, 10, pp. 1-12; Group, M.L., Intel, M., Ireland, D., Palla, A., Moloney, D., Fanucci, L., Fully convolutional denoising autoencoder for 3D scene reconstruction from a single depth image (2017) No. Icsai, pp. 566-575; Firman, M., Aodha, O.M., Julier, S., Brostow, G.J., Structured prediction of unobserved voxels from a single depth image (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5431-5440. , http://ieeexplore.ieee.org/document/7780955/; Liu, S., Chen, C., Kehtarnavaz, N., (2016) A Computationally Efficient Denoising and Hole-filling Method for Depth Image Enhancement, 9897, p. 98970V. , http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2230495; Jaiswal, M., Xie, J., Sun, M.T., 3D object modeling with a Kinect camera (2014) 2014 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference, APSIPA 2014; Xie, J., Hsu, Y., Feris, R., Sun, M., Fine registration of 3D point clouds with iterative closest point using an RGB-D camera (2013) Circuits and Systems (ISCAS), pp. 1-4. , http://staff.washington.edu/junx/publication/FineRegistrationISCAS13.pdf%5Cnhttp://ieeexplore.ieee.org/xpls/absall.jsp?arnumber=6572486; Avron, H., Sharf, A., Greif, C., Cohen-Or, D., 1-Sparse reconstruction of sharp point set surfaces (2010) ACM Transactions on Graphics, 29 (5), pp. 1-12. , http://portal.acm.org/citation.cfm?doid=1857907.1857911; Isenburg, M., Liu, Y., Shewchuk, J., Snoeyink, J., Streaming computation of Delaunay triangulations (2006) ACM Transactions on Graphics, 25 (3), p. 1049. , http://portal.acm.org/citation.cfm?doid=1141911.1141992; Kowalski, M., Naruniec, J., Daniluk, M., Live Scan3D: A fast and inexpensive 3D data acquisition system for multiple kinect v2 sensors (2015) Proceedings - 2015 International Conference on 3D Vision, 3DV, 2015, pp. 318-325; Besl, P., McKay, N., (1992) A Method for Registration of 3-D Shapes, pp. 239-256; Burns, C., (2017) Texture Super-Resolution for 3D Reconstruction, pp. 4-7; Bouguet, J.-Y., Tarasenko, V., Lucas, B.D., Kanade, T., Pyramidal implementation of the lucas kanade feature tracker description of the algorithm (1981) Imaging, 130 (10), pp. 1-9; Plyer, A., Le Besnerais, G., Champagnat, F., Massively parallel Lucas Kanade optical flow for realtime video processing applications (2016) Journal of Real-Time Image Processing, 11 (4), pp. 713-730; Tulsiani, S., Zhou, T., Efros, A.A., Malik, J., Multi-view supervision for single-view reconstruction via differentiable ray consistency (2017) Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, 2017, pp. 209-217. , Janua; Martin-Brualla, R., Gallup, D., Seitz, S.M., 3D time-lapse reconstruction from internet photos (2017) International Journal of Computer Vision, 125 (1-3), pp. 52-64; Xu, X., Che, R., Nian, R., He, B., (2016) Underwater 3D Object Reconstruction with Multiple Views in Video Stream Via Structure from Motion, pp. 0-4; Lapandic, D., Velagic, J., Balta, H., Framework for automated reconstruction of 3D model from multiple 2D aerial images (2017) Proceedings Elmar - International Symposium Electronics in Marine, 2017, pp. 18-20. , Septe, no. September","Ham, H.; Computer Science Department, Indonesia; email: hanry.ham@binus.edu",,,"Institute of Advanced Engineering and Science",,,,,20888708,,,,"English","Int. J. Electr. Comput. Eng.",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85066294717
"Setiawan A.S., Elysia, Wesley J., Purnama Y.","56979072200;56979346400;56978958500;56979324900;","Mammogram Classification using Law's Texture Energy Measure and Neural Networks",2015,"Procedia Computer Science","59",,,"92","97",,42,"10.1016/j.procs.2015.07.341","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948418724&doi=10.1016%2fj.procs.2015.07.341&partnerID=40&md5=24fba1ac2cdee77e500876452a211f00","Master of Information Technology, Bina Nusantara University, Jl KH Syahdan 9, Jakarta, 11480, Indonesia","Setiawan, A.S., Master of Information Technology, Bina Nusantara University, Jl KH Syahdan 9, Jakarta, 11480, Indonesia; Elysia, Master of Information Technology, Bina Nusantara University, Jl KH Syahdan 9, Jakarta, 11480, Indonesia; Wesley, J., Master of Information Technology, Bina Nusantara University, Jl KH Syahdan 9, Jakarta, 11480, Indonesia; Purnama, Y., Master of Information Technology, Bina Nusantara University, Jl KH Syahdan 9, Jakarta, 11480, Indonesia","Mammography is the best approach in early detection of breast cancer. In mammography classification, accuracy is determined by feature extraction methods and classifier. In this study, we propose a mammogram classification using Law's Texture Energy Measure (LAWS) as texture feature extraction method. Artificial Neural Network (ANN) is used as classifier for normal- abnormal and benign-malignant images. Training data for the mammogram classification model is retrieved from MIAS database. Result shows that LAWS provides better accuracy than other similar method such as GLCM. LAWS provide93.90% accuracy for normal-abnormal and 83.30% for benign-malignant classification, while GLCM only provides 72.20% accuracy for normal-abnormal and 53.06% for benign-malignant classification. © 2015 The Authors. Published by Elsevier B.V.","GLCM; LAWS; Mammography; Texture","Artificial intelligence; Extraction; Feature extraction; Mammography; Neural networks; Textures; X ray screens; Early detection of breast cancer; Feature extraction methods; GLCM; LAWS; Mammogram classifications; Mammography classification; Texture energy measure; Texture feature extraction; Classification (of information)",,,,,,"Santhi, B., Nithya, R., Comparative Study on Feature Extraction Method for Breast Cancer Classification (2011) Journal of Theoretical and Applied Information Technology, 33 (2), pp. 220-226; Kandaswamy, A., Sheshadri, H., Detection of breast cancer by mammogram image segmentation (2005) J Cancer Res Ther, 1 (4), pp. 232-234; Chan, H.-P., (1997) Computerized Classification of Malignant and Benign Micriocalcifications on Mammograms: Texture Analysis Using An Artificial Neural Network; Mohd, K.A., Besar, R., Wan, Z.W., Ahmad, N., Identification of masses in digital mammogram using gray level co-occurrence matrices (2009) Biomedical Imaging and Intervention Journal, pp. 1-13; Elnemr, H.A., (2013) Statistical Analysis of Law's Mask Texture Features for Cancer and Water Lung Detection, 10 (6); Zhang, G., Patuwo, B.E., Hu, M.Y., (1998) Forecasting with Artificial Neural Networks: The State of the Art; Laws, K.I., (1980) Textured Image Segmentation; Wei, C.-H., Li, C.-T., Wilson, R., (2006) A Content-Based Approach to Medical Image Database Retrieval.","Elysia; Master of Information Technology, Jl KH Syahdan 9, Indonesia; email: elysia@binus.edu","Budiharto W.","","Elsevier","1st International Conference on Computer Science and Computational Intelligence, ICCSCI 2015","24 August 2015 through 26 August 2015",,,18770509,,,,"English","Procedia Comput. Sci.",Conference Paper,"Final","All Open Access, Bronze",Scopus,2-s2.0-84948418724
